#!/usr/bin/env python3
"""
gRPC Task Service Server Implementation

This server demonstrates:
1. All four gRPC communication patterns (Unary, Server Streaming, Client Streaming, Bidirectional)
2. In-memory task storage with thread-safe operations
3. Authentication using metadata/headers
4. Proper error handling with gRPC status codes
5. Logging and monitoring
6. Graceful shutdown handling
"""

import asyncio
import grpc
import logging
import signal
import sys
import time
import uuid
from concurrent import futures
from datetime import datetime, timedelta
from typing import Dict, List, AsyncIterator, Optional
import threading
from collections import defaultdict

# Add the generated protobuf files to the path
sys.path.append('./generated')

# Import generated protobuf classes
# These will be generated by running protoc
from generated import task_service_pb2
from generated import task_service_pb2_grpc

# Configure structured logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class TaskServicer(task_service_pb2_grpc.TaskServiceServicer):
    """
    Implementation of the TaskService gRPC service.

    This class handles all RPC methods defined in the proto file.
    Uses in-memory storage for simplicity (could be replaced with a real database).
    """

    def __init__(self):
        # In-memory task storage (in production, use a real database)
        self.tasks: Dict[str, task_service_pb2.Task] = {}

        # Lock for thread-safe operations
        self.lock = threading.RLock()

        # Event subscribers for real-time updates
        self.event_subscribers: Dict[str, asyncio.Queue] = {}

        # Statistics for monitoring
        self.stats = defaultdict(int)

        logger.info("TaskServicer initialized")

    def _generate_id(self) -> str:
        """Generate a unique task ID."""
        return str(uuid.uuid4())

    def _current_timestamp(self):
        """Get current timestamp in protobuf format."""
        timestamp = task_service_pb2.google_dot_protobuf_dot_timestamp__pb2.Timestamp()
        timestamp.FromDatetime(datetime.utcnow())
        return timestamp

    def _authenticate(self, context: grpc.ServicerContext) -> Optional[str]:
        """
        Simple authentication check using metadata.
        In production, implement proper JWT validation.

        Returns user_id if authenticated, None otherwise.
        """
        # Get metadata from the request
        metadata = dict(context.invocation_metadata())

        # Check for authorization header
        auth_token = metadata.get('authorization', '')

        # Simple token validation (in production, validate JWT properly)
        if auth_token.startswith('Bearer '):
            # Extract user from token (simplified for demo)
            user_id = auth_token.replace('Bearer ', '').split('-')[0]
            return user_id

        # For demo purposes, allow unauthenticated requests with default user
        return 'anonymous'

    def _emit_event(self, event: task_service_pb2.TaskEvent):
        """Emit an event to all subscribers."""
        # This would be async in a real implementation
        for subscriber_id, queue in self.event_subscribers.items():
            try:
                queue.put_nowait(event)
            except asyncio.QueueFull:
                logger.warning(f"Event queue full for subscriber {subscriber_id}")

    # --- Unary RPC Methods ---

    def CreateTask(
        self,
        request: task_service_pb2.CreateTaskRequest,
        context: grpc.ServicerContext
    ) -> task_service_pb2.Task:
        """
        Unary RPC: Create a new task.

        Demonstrates:
        - Input validation
        - Authentication check
        - Thread-safe storage
        - Event emission for real-time updates
        """
        logger.info(f"CreateTask called with title: {request.title}")

        # Authenticate user
        user_id = self._authenticate(context)
        if not user_id:
            context.abort(grpc.StatusCode.UNAUTHENTICATED, "Authentication required")

        # Validate input
        if not request.title:
            context.abort(grpc.StatusCode.INVALID_ARGUMENT, "Title is required")

        # Create the task
        task = task_service_pb2.Task()
        task.id = self._generate_id()
        task.title = request.title
        task.description = request.description
        task.status = task_service_pb2.TASK_STATUS_TODO
        task.priority = request.priority or task_service_pb2.PRIORITY_MEDIUM
        task.labels.extend(request.labels)
        task.created_by = user_id
        task.assigned_to = request.assigned_to or user_id
        task.created_at.CopyFrom(self._current_timestamp())
        task.updated_at.CopyFrom(self._current_timestamp())

        if request.HasField('due_date'):
            task.due_date.CopyFrom(request.due_date)

        # Copy metadata
        for key, value in request.metadata.items():
            task.metadata[key] = value

        # Store the task (thread-safe)
        with self.lock:
            self.tasks[task.id] = task
            self.stats['tasks_created'] += 1

        # Emit event for real-time subscribers
        event = task_service_pb2.TaskEvent(
            event_type=task_service_pb2.EVENT_TYPE_CREATED,
            task=task,
            timestamp=self._current_timestamp(),
            triggered_by=user_id
        )
        self._emit_event(event)

        logger.info(f"Task created with ID: {task.id}")
        return task

    def GetTask(
        self,
        request: task_service_pb2.GetTaskRequest,
        context: grpc.ServicerContext
    ) -> task_service_pb2.Task:
        """
        Unary RPC: Get a task by ID.

        Demonstrates proper error handling with gRPC status codes.
        """
        logger.info(f"GetTask called for ID: {request.id}")

        with self.lock:
            task = self.tasks.get(request.id)

        if not task:
            context.abort(
                grpc.StatusCode.NOT_FOUND,
                f"Task with ID '{request.id}' not found"
            )

        self.stats['tasks_retrieved'] += 1
        return task

    def UpdateTask(
        self,
        request: task_service_pb2.UpdateTaskRequest,
        context: grpc.ServicerContext
    ) -> task_service_pb2.Task:
        """
        Unary RPC: Update an existing task.

        Demonstrates:
        - Partial updates using optional fields
        - Optimistic locking could be added here
        """
        logger.info(f"UpdateTask called for ID: {request.id}")

        user_id = self._authenticate(context)

        with self.lock:
            task = self.tasks.get(request.id)
            if not task:
                context.abort(
                    grpc.StatusCode.NOT_FOUND,
                    f"Task with ID '{request.id}' not found"
                )

            # Apply updates only for provided fields
            if request.HasField('title'):
                task.title = request.title

            if request.HasField('description'):
                task.description = request.description

            if request.HasField('status'):
                task.status = request.status

            if request.HasField('priority'):
                task.priority = request.priority

            if request.labels:
                task.labels[:] = request.labels

            if request.HasField('assigned_to'):
                task.assigned_to = request.assigned_to

            if request.HasField('due_date'):
                task.due_date.CopyFrom(request.due_date)

            # Update metadata
            for key, value in request.metadata.items():
                task.metadata[key] = value

            # Update timestamp
            task.updated_at.CopyFrom(self._current_timestamp())

            self.stats['tasks_updated'] += 1

        # Emit update event
        event = task_service_pb2.TaskEvent(
            event_type=task_service_pb2.EVENT_TYPE_UPDATED,
            task=task,
            timestamp=self._current_timestamp(),
            triggered_by=user_id
        )
        self._emit_event(event)

        return task

    def DeleteTask(
        self,
        request: task_service_pb2.DeleteTaskRequest,
        context: grpc.ServicerContext
    ) -> task_service_pb2.google_dot_protobuf_dot_empty__pb2.Empty:
        """
        Unary RPC: Delete a task.

        Returns Empty message as defined in proto.
        """
        logger.info(f"DeleteTask called for ID: {request.id}")

        user_id = self._authenticate(context)

        with self.lock:
            task = self.tasks.pop(request.id, None)
            if not task:
                context.abort(
                    grpc.StatusCode.NOT_FOUND,
                    f"Task with ID '{request.id}' not found"
                )

            self.stats['tasks_deleted'] += 1

        # Emit delete event
        event = task_service_pb2.TaskEvent(
            event_type=task_service_pb2.EVENT_TYPE_DELETED,
            task=task,
            timestamp=self._current_timestamp(),
            triggered_by=user_id
        )
        self._emit_event(event)

        return task_service_pb2.google_dot_protobuf_dot_empty__pb2.Empty()

    def ListTasks(
        self,
        request: task_service_pb2.ListTasksRequest,
        context: grpc.ServicerContext
    ) -> task_service_pb2.ListTasksResponse:
        """
        Unary RPC: List tasks with filtering and pagination.

        Demonstrates:
        - Filtering by multiple criteria
        - Pagination with tokens
        - Sorting
        """
        logger.info("ListTasks called")

        with self.lock:
            # Get all tasks as a list for filtering
            all_tasks = list(self.tasks.values())

        # Apply filters
        filtered_tasks = []
        for task in all_tasks:
            # Filter by status
            if request.statuses and task.status not in request.statuses:
                continue

            # Filter by priority
            if request.priorities and task.priority not in request.priorities:
                continue

            # Filter by labels (task must have at least one of the requested labels)
            if request.labels:
                if not any(label in task.labels for label in request.labels):
                    continue

            # Filter by assigned user
            if request.assigned_to and task.assigned_to != request.assigned_to:
                continue

            filtered_tasks.append(task)

        # Sort tasks
        if request.order_by == 'created_at':
            filtered_tasks.sort(
                key=lambda t: t.created_at.ToDatetime(),
                reverse=request.descending
            )
        elif request.order_by == 'priority':
            filtered_tasks.sort(
                key=lambda t: t.priority,
                reverse=request.descending
            )

        # Implement pagination
        page_size = request.page_size or 10
        start_index = 0

        if request.page_token:
            # Simple token implementation (in production, use encrypted tokens)
            try:
                start_index = int(request.page_token)
            except ValueError:
                context.abort(grpc.StatusCode.INVALID_ARGUMENT, "Invalid page token")

        # Get page of results
        end_index = start_index + page_size
        page_tasks = filtered_tasks[start_index:end_index]

        # Create next page token if there are more results
        next_page_token = ""
        if end_index < len(filtered_tasks):
            next_page_token = str(end_index)

        # Build response
        response = task_service_pb2.ListTasksResponse(
            tasks=page_tasks,
            next_page_token=next_page_token,
            total_count=len(filtered_tasks)
        )

        self.stats['tasks_listed'] += 1
        return response

    # --- Server Streaming RPC ---

    def WatchTasks(
        self,
        request: task_service_pb2.WatchTasksRequest,
        context: grpc.ServicerContext
    ) -> AsyncIterator[task_service_pb2.TaskEvent]:
        """
        Server Streaming RPC: Stream task events to the client.

        Demonstrates:
        - Long-lived streaming connections
        - Event filtering
        - Cleanup on client disconnect
        """
        logger.info("WatchTasks called")

        subscriber_id = self._generate_id()
        event_queue = asyncio.Queue(maxsize=100)

        # Register subscriber
        self.event_subscribers[subscriber_id] = event_queue

        try:
            # Send initial state if requested
            if request.include_initial:
                with self.lock:
                    for task in self.tasks.values():
                        # Apply filters
                        if request.task_ids and task.id not in request.task_ids:
                            continue
                        if request.statuses and task.status not in request.statuses:
                            continue
                        if request.labels and not any(
                            label in task.labels for label in request.labels
                        ):
                            continue

                        # Send initial event
                        event = task_service_pb2.TaskEvent(
                            event_type=task_service_pb2.EVENT_TYPE_CREATED,
                            task=task,
                            timestamp=self._current_timestamp(),
                            triggered_by="system"
                        )
                        yield event

            # Stream events until client disconnects
            while context.is_active():
                try:
                    # Wait for events with timeout
                    event = event_queue.get(timeout=1.0)

                    # Apply filters
                    task = event.task
                    if request.task_ids and task.id not in request.task_ids:
                        continue
                    if request.statuses and task.status not in request.statuses:
                        continue
                    if request.labels and not any(
                        label in task.labels for label in request.labels
                    ):
                        continue

                    yield event

                except asyncio.TimeoutError:
                    # No events, continue waiting
                    continue
                except Exception as e:
                    logger.error(f"Error in WatchTasks: {e}")
                    break

        finally:
            # Clean up subscriber
            del self.event_subscribers[subscriber_id]
            logger.info(f"WatchTasks subscriber {subscriber_id} disconnected")

    # --- Client Streaming RPC ---

    def BulkCreateTasks(
        self,
        request_iterator,
        context: grpc.ServicerContext
    ) -> task_service_pb2.BulkCreateResponse:
        """
        Client Streaming RPC: Create multiple tasks from a stream.

        Demonstrates:
        - Processing streaming input
        - Batch operations
        - Error handling per item
        """
        logger.info("BulkCreateTasks called")

        user_id = self._authenticate(context)
        created_tasks = []
        errors = []
        index = 0

        # Process each request in the stream
        for request in request_iterator:
            try:
                # Validate
                if not request.title:
                    raise ValueError("Title is required")

                # Create task (reuse logic from CreateTask)
                task = task_service_pb2.Task()
                task.id = self._generate_id()
                task.title = request.title
                task.description = request.description
                task.status = task_service_pb2.TASK_STATUS_TODO
                task.priority = request.priority or task_service_pb2.PRIORITY_MEDIUM
                task.labels.extend(request.labels)
                task.created_by = user_id
                task.assigned_to = request.assigned_to or user_id
                task.created_at.CopyFrom(self._current_timestamp())
                task.updated_at.CopyFrom(self._current_timestamp())

                # Store task
                with self.lock:
                    self.tasks[task.id] = task

                created_tasks.append(task)

                # Emit event
                event = task_service_pb2.TaskEvent(
                    event_type=task_service_pb2.EVENT_TYPE_CREATED,
                    task=task,
                    timestamp=self._current_timestamp(),
                    triggered_by=user_id
                )
                self._emit_event(event)

            except Exception as e:
                # Record error for this item
                error = task_service_pb2.BulkError(
                    index=index,
                    error_message=str(e)
                )
                errors.append(error)

            index += 1

        # Build response
        response = task_service_pb2.BulkCreateResponse(
            tasks=created_tasks,
            success_count=len(created_tasks),
            errors=errors
        )

        logger.info(
            f"BulkCreateTasks completed: "
            f"{len(created_tasks)} created, {len(errors)} errors"
        )
        return response

    # --- Bidirectional Streaming RPC ---

    def ProcessTaskStream(
        self,
        request_iterator,
        context: grpc.ServicerContext
    ) -> AsyncIterator[task_service_pb2.TaskResult]:
        """
        Bidirectional Streaming RPC: Interactive task processing.

        Demonstrates:
        - Two-way streaming communication
        - Command processing
        - Real-time responses
        """
        logger.info("ProcessTaskStream called")

        user_id = self._authenticate(context)

        # Process commands as they arrive
        for command in request_iterator:
            try:
                result = task_service_pb2.TaskResult()

                # Process based on command type
                if command.HasField('create'):
                    # Create task
                    task = self.CreateTask(command.create, context)
                    result.success = True
                    result.task.CopyFrom(task)

                elif command.HasField('update'):
                    # Update task
                    task = self.UpdateTask(command.update, context)
                    result.success = True
                    result.task.CopyFrom(task)

                elif command.HasField('delete'):
                    # Delete task
                    self.DeleteTask(command.delete, context)
                    result.success = True
                    # No task to return for delete

                elif command.HasField('get'):
                    # Get task
                    task = self.GetTask(command.get, context)
                    result.success = True
                    result.task.CopyFrom(task)

                else:
                    result.success = False
                    result.error_message = "Unknown command type"

                yield result

            except grpc.RpcError as e:
                # Handle gRPC errors
                result = task_service_pb2.TaskResult()
                result.success = False
                result.error_message = e.details()
                yield result

            except Exception as e:
                # Handle other errors
                result = task_service_pb2.TaskResult()
                result.success = False
                result.error_message = str(e)
                yield result

        logger.info("ProcessTaskStream completed")


async def serve():
    """
    Start the gRPC server with proper configuration.

    Demonstrates:
    - Thread pool configuration
    - Reflection for debugging
    - Graceful shutdown
    - Health checking
    """
    # Create gRPC server with thread pool
    server = grpc.aio.server(
        futures.ThreadPoolExecutor(max_workers=10),
        options=[
            ('grpc.max_send_message_length', 50 * 1024 * 1024),  # 50MB
            ('grpc.max_receive_message_length', 50 * 1024 * 1024),
            ('grpc.keepalive_time_ms', 10000),
            ('grpc.keepalive_timeout_ms', 5000),
            ('grpc.keepalive_permit_without_calls', True),
            ('grpc.http2.max_pings_without_data', 0),
        ]
    )

    # Add the task service
    task_service_pb2_grpc.add_TaskServiceServicer_to_server(
        TaskServicer(), server
    )

    # Enable server reflection for debugging (grpcurl, grpc-client-cli)
    # reflection.enable_server_reflection(SERVICE_NAMES, server)

    # Configure server address
    listen_addr = '[::]:50051'
    server.add_insecure_port(listen_addr)

    logger.info(f"Starting gRPC server on {listen_addr}")

    # Start server
    await server.start()

    # Setup graceful shutdown
    def signal_handler(sig, frame):
        logger.info("Shutting down server...")
        asyncio.create_task(server.stop(grace_period=5))

    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

    try:
        # Keep server running
        await server.wait_for_termination()
    except KeyboardInterrupt:
        logger.info("Server interrupted")
    finally:
        logger.info("Server stopped")


if __name__ == '__main__':
    # Run the server
    asyncio.run(serve())